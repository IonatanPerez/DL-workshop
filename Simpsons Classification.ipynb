{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de los Simpsons!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **IMPORTANTE**: Si este es el primer *notebook* que estudia, recomendamos arrancar con el *notebook* del *MNIST*, que contiene una complejidad inferior, el cual se puede encontrar [aca](./MNIST Classification.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se detalla la implementación de un modelo que pueda identificar a los personajes de los simpsons en base a imagenes.\n",
    "\n",
    "El *dataset* a usar se puede encontrar en el siguiente [link](https://www.kaggle.com/alexattia/the-simpsons-characters-dataset) de **Kaggle**. **Kaggle** es una página ampliamente útil donde se pueden encontrar *datasets* interesantes, participar en competencias, observar trabajos de otros usuarios, etc.\n",
    "\n",
    "El *dataset* está conformado por imágenes de episodios. Si bien el *dataset* incluye informacion para poder efectuar **multiple object detection**, en este *notebook* nos vamos a dedicar a solucionar el problema de **imagen classification**. Esto quiere decir que, en cada imagen, aparece unicamente **un** personje, nuestro objetivo es clasificarlo. (A diferencia de **object detection**, donde la tarea sería detectar en una imagen recuadros de **todos** los personajes que aparecen en el mismo).\n",
    "\n",
    "El modelo debería ser lo suficientemente potente como para detectar a los personajes incluso cuando no se encuentran en su representación más clara, como por ejemplo:\n",
    "\n",
    "![img](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTvs50EEmc52JZyQc7C992Lqod71vQZnzK9dDd7KuHeqTGG276Q)\n",
    "\n",
    "Para este problema, vamos a implementar una CNN (Red Neuronal Convolucional) utilizando Tensorflow. Cada paso va a estar detallado y explicado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requisitos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para utilizar este *notebook*, se necesita descargar el dataset del siguiente [link](https://www.kaggle.com/alexattia/the-simpsons-characters-dataset/data). Recuerde la locación donde está la carpeta (descomprimida) del *dataset* pues se va a requerir luego. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente comando importa las librerias requeridas por el resto del programa. Detallamos las más importantes:\n",
    "\n",
    "* **numpy**: para el manejo en CPU de los tensores (vectores multidimensionales)\n",
    "* **matplotlib**: para graficar en el notebook\n",
    "* **tensorflow**: para construir y entrenar la red neuronal\n",
    "* **utils**: modulo propio presente en `utils.py` con funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-74383be1b0ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a cargar los personajes que forman parte de este dataset. Para esto, cambie la siguiente variable global con la locación de su carpeta donde esta el *dataset*. Por ejemplo, `~/Data/simpsons-dataset`. Asegúrese de que la carpeta `simpsons_dataset` se encuentro de la carpeta que define en la variable `DATA_DIR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your directory here. For example:\n",
    "DATA_DIR = \"/Users/user/data/the-simpsons-characters-dataset/simpsons_dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cargar los personajes, ejecutar la siguiente función perteneciente al módulo `utils`. Este metodo va a cargar un mapa con los personajes. Se puede pasar un segundo argumento con la cantidad mínima de imágenes que necesita tener un personaje para ser considerado (cuantas más imagenes de personaje, más robusto el clasificador)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_characters = utils.load_characters(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos los personajes que cargamos. Cada personaje esta identificado con un `id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in map_characters.items():\n",
    "    print(\"{} -> {}\".format(k, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, vamos a cargar las imagenes a memoria. Utilizamos la siguiente funcion de `utils`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics, labels = utils.load_pictures(DATA_DIR, map_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pics` es un `numpy array` que contiene las imagenes en el formato NHWC (Numero de imagenes x Altura x Ancho x Canales). \n",
    "\n",
    "`labels` es un `numpy array` con el *ground truth* con *One-hot encoding*, en el cual cada valor de verdad se representa como una distribucion de probabilidades por todas las posibles clases. Por ejemplo, para representar el *label* '3', el vector seria [0 0 0 1 0 0 0 0 ... 0 0 0] (osea, todos las clases en 0, menos la correspondiente, en 1).\n",
    "\n",
    "Veamos las dimensiones de cada uno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Images shape:\")\n",
    "print(pics.shape)\n",
    "print(\"Labels shape:\")\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos algunas imagenes del *dataset* con su respectivo *ground truth*. Para ver el codigo, ir a `utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.show_random_characters(pics, labels, map_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como se representa el valor del pixel en las imagenes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos antes, son imagenes en escala de grises (esto significa que tienen un solo canal). Ahora bien, veamos si los valores estan representados entre [0, 255] o entre [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(pics[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto quiere decir que los valores no están normalizados! Más adelante vamos a tener que normalizarlos, es decir, tener valores entre 0 y 1. Esto es muy usual en Machine Learning, pues evita problemas numéricos y puede ayudar a la convergencia en la búsqueda de la solución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando en Entrenamiento / Validación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a separar el *dataset* en 2:\n",
    "\n",
    "1. *train*: van a ser las imagenes propias del entrenamiento.\n",
    "2. *val*: estas imagenes no forman parte del entrenamiento, sino que sirven para medir la performance del modelo con *data* desconocida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pics_train, labels_train, pics_val, labels_val = utils.split(pics, labels, p=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos las dimensiones de los nuevos conjuntos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data:\")\n",
    "print(\"X: {}\".format(pics_train.shape))\n",
    "print(\"Y: {}\".format(labels_train.shape))\n",
    "print()\n",
    "print(\"Validation data:\")\n",
    "print(\"X: {}\".format(pics_val.shape))\n",
    "print(\"Y: {}\".format(labels_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiendo el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definamos las siguientes variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W, C = pics[0].shape\n",
    "NUM_CLASSES = len(map_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) La arquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La arquitectura, como se dijo antes, va a ser una CNN (Red Neuronal Convolucional). La misma va a consistir en una serie de convoluciones (con tecnicas de *pooling*, para reducir el dominio, para más información, [acá](http://ufldl.stanford.edu/wiki/index.php/Pooling)) acompañado de un clasificador de capas densas (*fully connected layers*).\n",
    "\n",
    "La arquitectura se puede resumir en el siguiente esquema:\n",
    "\n",
    "![img](http://adventuresinmachinelearning.com/wp-content/uploads/2017/04/Typical_cnn.png)\n",
    "\n",
    "Estas topologías de redes (Convoluciones + Capas densas) son **estándar** para solucionar el problema de *Image Classification*. Para más información sobre CNN, pueden seguir el siguiente [tutorial](https://www.tensorflow.org/tutorials/layers).\n",
    "\n",
    "La entrada de la red (el *input*) va a ser directamente la imagen. El *output* de la red va a ser el *one-hot encoding* conteniendo la clase de la imagen de entrada.\n",
    "\n",
    "El flujo sería el siguiente:\n",
    "\n",
    "1. Tomamos una imagen (que tiene un tamaño de HxW).\n",
    "2. Se introduce en la red.\n",
    "3. Se aplican una serie de convoluciones (filtros) acompañadas de *max pooling* para hacer *downsampling*.\n",
    "4. Luego de los ultimos filtros de convolucion, se aplana el contenido (conocido como *activation map*).\n",
    "5. Este vector plano entra a las capas densas de la red y fluye hacia la salida.\n",
    "6. La capa de salida va a ser un vector de N elementos (siendo N la cantidad de personajes), donde cada uno representa un *score* de que esa imagen pertenezca a esa clase. Cuanto mayor sea el *score*, buscamos que sea más probable que la imagen pertenezca a esa clase (es decir, que sea ESE digito). Cuando la red esté entrenada, la clase (o el dígito) correcto va a ser aquel que tengo mayor *score*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_architecture():\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    x = tf.placeholder(tf.uint8, shape=[None, H, W, 3], name=\"x\")\n",
    "    y = tf.placeholder(tf.uint8, shape=[None, NUM_CLASSES], name=\"y\")\n",
    "    \n",
    "    dropout_rate = tf.placeholder_with_default(0.3, shape=(), name=\"dropout_rate\")\n",
    "    \n",
    "    is_training = tf.placeholder_with_default(False, shape=(), name='is_training')\n",
    "    \n",
    "    init = tf.contrib.layers.xavier_initializer()\n",
    "    \n",
    "    out = tf.divide(x, 255)\n",
    "    \n",
    "    out = tf.layers.conv2d(out, filters=8, kernel_size=[3,3], activation=tf.nn.relu, kernel_initializer=init, padding=\"same\")\n",
    "    out = tf.layers.max_pooling2d(out, pool_size=(2, 2), strides=[2,2])\n",
    "        \n",
    "    out = tf.layers.conv2d(out, filters=16, kernel_size=[3,3], activation=tf.nn.relu, kernel_initializer=init, padding=\"same\")\n",
    "    out = tf.layers.max_pooling2d(out, pool_size=(2, 2), strides=[2,2])\n",
    "        \n",
    "    out = tf.layers.conv2d(out, filters=32, kernel_size=[3,3], activation=tf.nn.relu, kernel_initializer=init, padding=\"same\")\n",
    "    out = tf.layers.max_pooling2d(out, pool_size=(2, 2), strides=[2,2])\n",
    "        \n",
    "    out = tf.layers.conv2d(out, filters=64, kernel_size=[3,3], activation=tf.nn.relu, kernel_initializer=init, padding=\"same\")\n",
    "    out = tf.layers.max_pooling2d(out, pool_size=(2, 2), strides=[2,2])\n",
    "        \n",
    "    out = tf.contrib.layers.flatten(out)\n",
    "    \n",
    "    out = tf.layers.dropout(out, rate=dropout_rate, training=is_training)\n",
    "\n",
    "    out = tf.layers.dense(out, units=512, activation=tf.nn.relu, kernel_initializer=init)\n",
    "    \n",
    "    out = tf.layers.dropout(out, rate=dropout_rate, training=is_training)\n",
    "\n",
    "    out = tf.layers.dense(out, units=512, activation=tf.nn.relu, kernel_initializer=init)\n",
    "\n",
    "    out = tf.layers.dropout(out, rate=dropout_rate, training=is_training)\n",
    "    \n",
    "    out = tf.layers.dense(out, units=512, activation=tf.nn.relu, kernel_initializer=init)\n",
    "    \n",
    "    out = tf.layers.dropout(out, rate=dropout_rate, training=is_training)\n",
    "    \n",
    "    out = tf.layers.dense(out, units=512, activation=tf.nn.relu, kernel_initializer=init)\n",
    "\n",
    "    out = tf.layers.dropout(out, rate=dropout_rate, training=is_training)\n",
    "    \n",
    "    out = tf.layers.dense(out, units=NUM_CLASSES, kernel_initializer=init, name=\"out\")\n",
    "    \n",
    "    return x, y, is_training, dropout_rate, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) La función de costo (*loss*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funcion de costo para este problema va a ser la entropía cruzada aplicada a la funcion softmax sobre la capa de salida. Expliquemos un poco esto:\n",
    "\n",
    "En primer lugar, se computa la funcion softmax sobre la capa de salida (que son los *scores* de las clases). Esta funcion tiene la siguiente pinta:\n",
    "\n",
    "![img](https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3)\n",
    "\n",
    "Esta funcion mapea los *scores* a una distribucion de probabilidad, intensificando el valor del maximo (por ejemplo, si los scores hubieran sido [1.3, -0.2, 5.2], la funcion daria un vector ~[0.0197, 0.0044, 0.976]. Ahora, el *output* de la red está en terminos de probabilidad, al igual que el *ground truth*! (acuerdense que está en formato *One-hot encoding*).\n",
    "\n",
    "Gracias a esto, definimos la entropia cruzada, que es una forma de relacionar dos distribuciones de probabilidad:\n",
    "\n",
    "![img](https://wikimedia.org/api/rest_v1/media/math/render/svg/0cb6da032ab424eefdca0884cd4113fe578f4293)\n",
    "\n",
    "En resumen, cuando la probabilidad de la clase correcta en el *output* sea relativamente baja, la entropia cruzada va a ser altisima. Cuando sea alta, la entropia va a ser baja. Vamos a intentar minimizar la *loss* (que es la entropia cruzada luego del softmax), para buscar este ultimo comportamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_loss(y, out):\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=out, name=\"mean_loss\")\n",
    "    loss = tf.reduce_mean(loss, name=\"loss\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La *accuracy* mide el porcentaje de eficacia entre los *labels* y el *output* de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_accuracy(y, out):\n",
    "    pred = tf.argmax(out, axis=-1)\n",
    "    gt = tf.argmax(y, axis=-1)\n",
    "    \n",
    "    matches = tf.equal(pred, gt)\n",
    "    \n",
    "    return tf.reduce_mean(tf.cast(matches, tf.float32), name=\"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) La elección del minimizador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a estar utilizando *Adam*. Es una variante adaptativa a *Stochastic Gradient Descent* (SGD).\n",
    "\n",
    "Para más información acerca de los minimizadores, leer el siguiente excelente blog [aqui](http://ruder.io/optimizing-gradient-descent/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trainer(loss):\n",
    "    opt = tf.train.AdamOptimizer()\n",
    "    return opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones complementarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siguientes funciones son complementarias y no revisten de mayor importancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_scalars(m):\n",
    "    for k, v in m.items():\n",
    "        tf.summary.scalar(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_images(m):\n",
    "    for k, v in m.items():\n",
    "        tf.summary.image(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable_parameters():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        total_parameters += variable_parameters\n",
    "    return total_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente funcion junta todos los pasos anteriores para definir el modelo final. Esta funcion es la encargada de cargar el grafo en Tensorflow para luego correr la optimizacion.\n",
    "\n",
    "La funcion retorna aquellos nodos del grafo necesarios para ser corridos luego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    x, y, is_training, dropout_rate, out = load_architecture()\n",
    "    loss = load_loss(y, out)\n",
    "    acc = load_accuracy(y, out)\n",
    "    upd = load_trainer(loss)\n",
    "    \n",
    "    register_scalars({\"info_loss\": loss, \"info_acc\": acc})\n",
    "    register_images({\"input\": x})\n",
    "\n",
    "    info = tf.summary.merge_all()\n",
    "    \n",
    "    return x, y, is_training, dropout_rate, out, loss, acc, upd, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow requiere:\n",
    "\n",
    "1. Definir el grafo computacional (lo que hicimos antes)\n",
    "2. Correr el grafo a traves de una `Session`.\n",
    "\n",
    "A continuacion, definimos la sesión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_session():\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, definimos una funcion que encapsula todo el entrenamiento de la red, es decir, la optimizacion de la funcion de *loss* definida previamente.\n",
    "\n",
    "Esta funcion recibe la sesion, el modelo, la data, la cantidad de epocas, el tamaño del *batch* y los *writers*, que sirven para hacer uso de la herramienta de visualizacion *tensorboard*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sess, model, pics_train, labels_train, pics_val, labels_val, epochs, batch_size, train_writer, val_writer, use_dropout=False):\n",
    "    N, _, _, _ = pics_train.shape\n",
    "    idxs = np.arange(N)\n",
    "    \n",
    "    x, y, is_training, dropout_rate, out, loss, acc, upd, info = model\n",
    "    \n",
    "    d_rate = 0.4 if use_dropout else 0.\n",
    "    \n",
    "    i=0\n",
    "\n",
    "    for ep in tqdm(range(epochs)):\n",
    "        np.random.shuffle(idxs)\n",
    "        pics_train = pics_train[idxs]\n",
    "        labels_train = labels_train[idxs]\n",
    "\n",
    "        for b in range(0, N, batch_size):\n",
    "            X_batch = pics_train[b:b+batch_size]\n",
    "            Y_batch = labels_train[b:b+batch_size]\n",
    "\n",
    "            if X_batch.shape[0] < BATCH_SIZE:\n",
    "                break\n",
    "\n",
    "            graph_info, _ = sess.run([info, upd], feed_dict={x: X_batch, y: Y_batch, is_training: True, dropout_rate: d_rate})\n",
    "            train_writer.add_summary(graph_info, i)\n",
    "            \n",
    "            graph_info, = sess.run([info], feed_dict={x: pics_val, y: labels_val, is_training: False, dropout_rate: d_rate})\n",
    "            val_writer.add_summary(graph_info, i)\n",
    "            \n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ultimo, definimos una funcion que nos va a permitir probar el modelo entrenado. Esta funcion simplemente ejecuta la red con las imagenes que se proveen como parametro. Retorna las inferencias (es decir, las clases \"ganadoras\") para cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(imgs, model):\n",
    "    x, y, is_training, dropout_rate, out, loss, acc, upd, info = model\n",
    "\n",
    "    N, H, W, _ = imgs.shape\n",
    "    fig=plt.figure(figsize=(20, 20))\n",
    "    columns = 3\n",
    "    rows = 3\n",
    "    for i in range(1, columns*rows +1):\n",
    "        idx = np.random.choice(range(N)) \n",
    "        img = imgs[idx]\n",
    "        img_batch = np.reshape(img, [1, H, W, 3])\n",
    "        graph_out, = sess.run([out], feed_dict={x: img_batch})\n",
    "        char = np.argmax(np.squeeze(graph_out))\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(img)\n",
    "        plt.title(map_characters[char])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Overfitteando* data primero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver que el modelo esta bien implementado y converge a una solución, primero tratemos que aprenda una pequeña porción del *dataset*. Esta técnica es muy usual para validar la implmenetación del modelo.\n",
    "\n",
    "Obviamente, con pocos datos y un modelo potente, vamos a sufrir *overfitting*. Pero en este escenario no es un problema, pues solo estamos validando el modelo, y lo que queremos es ver si es capaz de llegar a una solucion. Es decir, estamos buscando el *overfitting*.\n",
    "\n",
    "Si no esta familiarizado con el termino **overfitting**, recomendamos leer el siguiente [post](https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomemos primero una pequeña porción del set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pics_train_sm, labels_train_sm = utils.get_small_dataset(pics_train, labels_train, p=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analicemos su tamaño:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"New training dataset size: {}\".format(pics_train_sm.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la cantidad de parametros *aprendibles* que tiene el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model()\n",
    "print(\"Trainable parameters: {}\".format(trainable_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenemos el modelo ahora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "LOGS_DIR = \"logs\"\n",
    "\n",
    "sess = load_session()\n",
    "\n",
    "t_writer = tf.summary.FileWriter(os.path.join(LOGS_DIR, \"overfit\", \"train\"), graph=sess.graph)\n",
    "v_writer = tf.summary.FileWriter(os.path.join(LOGS_DIR, \"overfit\", \"val\"), graph=sess.graph)\n",
    "\n",
    "train(sess, model, pics_train_sm, labels_train_sm, pics_val, labels_val, EPOCHS, BATCH_SIZE, t_writer, v_writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la carpeta `logs` van a poder tener informacion util para analizar el proceso de entrenamiento. Para verla, se necesita levantar `tensorboard`. Para esto, ir a la consola y ejecutar:\n",
    "\n",
    "```\n",
    "$ tensorboard --logdir ./logs\n",
    "```\n",
    "\n",
    "Se les va a abrir un *tab* en el navegador donde van a poder ver los graficos de entrenamiento en funcion de las épocas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos que es lo que aprendio (o memorizó en este caso), la red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(pics_train_sm, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, sabemos que estamos *overfitteando* porque el modelo no puede resolver imagenes que no ha visto antes. Decimos en este caso que la red no tiene poder de **generalización**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(pics_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenando con toda la data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetimos el proceso pero con todas las imagenes de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model()\n",
    "sess = load_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 70\n",
    "BATCH_SIZE = 64\n",
    "LOGS_DIR = \"logs\"\n",
    "\n",
    "t_writer = tf.summary.FileWriter(os.path.join(LOGS_DIR, \"all-1\", \"train\"), graph=sess.graph)\n",
    "v_writer = tf.summary.FileWriter(os.path.join(LOGS_DIR, \"all-1\", \"val\"), graph=sess.graph)\n",
    "\n",
    "train(sess, model, pics_train, labels_train, pics_val, labels_val, EPOCHS, BATCH_SIZE, t_writer, v_writer, use_dropout=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos visualmente algunos ejemplos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(pics_train, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos ahora si la red pudo generalizar. De ser así, debería tener una buena *performance* con imágenes que no ha visto duranete su proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(pics_val, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos a continuación cuáles son los ejemplos en el set de validación que la red no ha podido detectar correctamente.\n",
    "\n",
    "Pueden sacar alguna conclusión viendo estos ejemplos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, is_training, dropout_rate, out, loss, acc, upd, info = model\n",
    "\n",
    "graph_out, = sess.run([out], feed_dict={x: pics_val})\n",
    "pred = np.argmax(graph_out, axis=-1)\n",
    "gt = np.argmax(labels_val, axis=-1)\n",
    "\n",
    "\n",
    "mismatches = pics_val[pred != gt]\n",
    "\n",
    "print(mismatches.shape)\n",
    "\n",
    "predict(mismatches, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos la performance *overall* que tuvo el modelo en la data de validacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, is_training, dropout_rate, out, loss, acc, upd, info = model\n",
    "\n",
    "N, H, W, _ = pics_val.shape\n",
    "graph_out, = sess.run([acc], feed_dict={x: pics_val, y: labels_val})\n",
    "print(\"Overall accuracy: {0:.2f}%\".format(100 * np.squeeze(graph_out)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que en este *notebook* no se hizo una busqueda de hiperparámetros para optimizar el modelo. Bajo este escenario, podemos decir que nuestro set de validacion es finalmente nuestro set de *test*. Para reportar la performance del modelo, podemos utilizar la *accuracy* de este set.\n",
    "\n",
    "Si hubiésemos hecho una busqueda de hiperparámetros, tendríamos que haber dividir el *dataset* en *training, validation, testing*. Para más información de esto, ir [aquí](https://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
