{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación en MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset MNIST ([link](http://yann.lecun.com/exdb/mnist/)) es un **estándar** para evauar modelos de clasificación. \n",
    "\n",
    "Está compuesto por imagenes grises de 28x28 pixeles donde cada imagen posee un digito manuscrito (del 0 al 9) centrado en la misma.\n",
    "\n",
    "![img](https://tensorflow.rstudio.com/tensorflow/articles/images/MNIST.png)\n",
    "\n",
    "Este dataset es famoso debido a su gran cantidad de *samples* y a la capacidad de tener buena *performance* con modelos relativamente simples. Es muy usual que MNIST aparezca como dataset de prueba en tutoriales y/o cursos de Machine Learning y Deep Learning.\n",
    "\n",
    "Hoy en dia es un problema más que resuelto. Existen modelos que ya han conseguido un error < 0.2% en el set de *test*.\n",
    "\n",
    "Este notebook va a desarrollar una implementacion (en Tensorflow) de una red neuronal de capas totalmente conectadas para resolver el problema (tambien conocidas como *\"Fully Connected Networks\"* o *\"Dense Networks\"*). Cada paso va a estar detallado y explicado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente comando importa las librerias requeridas por el resto del programa. Detallamos las mas importantes:\n",
    "\n",
    "* **numpy**: para el manejo en CPU de los tensores (vectores multidimensionales)\n",
    "* **matplotlib**: para graficar en el notebook\n",
    "* **tensorflow**: para construir y entrenar la red neuronal\n",
    "* **utils**: modulo propio presente en `utils.py` con funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargando el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vamos a cargar el dataset. Para eso, usamos una funcion auxiliar del archivo `utils.py` que se va a encargar de realizar esto.\n",
    "\n",
    "Esta funcion retorna un 4-upla donde cada elemento es un *numpy array* y además:\n",
    "\n",
    "* *pics_train*: contiene las imagenes de *training*\n",
    "* *labels_train*: contiene los labels (el valor real, tambien llamado *ground truth*) de cada una de las iamgenes de *training*\n",
    "* *pics_test*: contiene las imagenes de *testing*. Estas imagenes solo se van a utilizar al final para medir performance, pero **no para entrenar**.\n",
    "* *labels_test*: contiene los labels de cada una de las imagenes de *testing*\n",
    "\n",
    "Estos objetos van a ser nuestros **datos** para el aprendizaje supervisado. En los objetos *\"pics\"* tenemos nuestros *inputs* y en los objetos *\"labels\"* tenemos nuestros *outputs*.\n",
    "\n",
    "La siguiente celda va a descargar de internet el dataset (la primera vez que es ejecutada), asi que es posible que tarde un tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From d:\\Proyectos\\DeepLearning\\DL-workshop\\utils.py:121: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "pics_train, labels_train, pics_test, labels_test = utils.load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos las dimensiones de cada uno de los *numpy arrays*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "(55000, 28, 28, 1)\n",
      "(55000, 10)\n",
      "\n",
      "Test data:\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data:\")\n",
    "print(pics_train.shape)\n",
    "print(labels_train.shape)\n",
    "print()\n",
    "print(\"Test data:\")\n",
    "print(pics_test.shape)\n",
    "print(labels_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay 55000 imagenes de *training* donde cada una es un tensor de 28x28x1 (que representa el valor del gris, en la ultima dimensión, de cada pixel en la imagen). Nota: si bien podría ser 28x28 (es decir, sin el \"x1\" del final), se acostumbra en la práctica a dejar siempre el formato NWHC (Number - Width - Height - Channels).\n",
    "\n",
    "A la vez, hay 55000 vectores de 10 que son los *labels* del *training*. El formato del label sigue el patrón *\"One-hot encoding\"*, en el cual cada valor de verdad se representa como una distribucion de probabilidades por todas las posibles clases. Por ejemplo, para representar el *label* '3', el vector seria [0 0 0 1 0 0 0 0 0 0 0] (osea, todos las clases en 0, menos la correspondiente, en 1). De nuevo, este formato es el estandar para representar los *labels* en un problema de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficando algunas imagenes de ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando una de las funciones auxiliares de `utils.py`, podemos observar algunas imagenes acompañadas de su correspondiente *label*, es decir, de su valor de verdad (o *ground truth*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.show_random_mnist(pics_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como se representa el valor del pixel en las imagenes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vimos antes, son imagenes en escala de grises (esto significa que tienen un solo canal). Ahora bien, veamos si los valores estan representados entre [0, 255] o entre [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.01568628 0.01960784 0.0509804  0.07058824 0.08235294\n",
      " 0.09019608 0.09803922 0.12156864 0.13333334 0.14509805 0.14901961\n",
      " 0.16078432 0.18823531 0.20000002 0.22352943 0.2392157  0.24313727\n",
      " 0.26666668 0.27058825 0.29411766 0.3019608  0.32156864 0.32941177\n",
      " 0.3372549  0.34901962 0.3529412  0.37647063 0.3803922  0.4156863\n",
      " 0.4431373  0.45098042 0.45882356 0.46274513 0.4666667  0.48627454\n",
      " 0.5019608  0.5411765  0.54509807 0.54901963 0.5568628  0.6156863\n",
      " 0.6509804  0.65882355 0.6627451  0.6901961  0.73333335 0.7411765\n",
      " 0.74509805 0.7803922  0.7843138  0.8078432  0.81568635 0.8235295\n",
      " 0.8352942  0.8431373  0.8588236  0.86274517 0.8705883  0.8745099\n",
      " 0.8862746  0.89019614 0.8941177  0.9058824  0.9176471  0.9215687\n",
      " 0.9333334  0.93725497 0.94117653 0.9450981  0.9490197  0.95294124\n",
      " 0.9607844  0.96470594 0.9725491  0.9803922  0.9843138  0.9921569\n",
      " 0.9960785 ]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(pics_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto quiere decir que los valores están normalizados! Es decir, valores entre 0 y 1. Esto es muy usual en Machine Learning, pues evita problemas numéricos y puede ayudar a la convergencia en la búsqueda de la solución."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiendo el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generemos algunas variables importantes que nos van a servir luego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, H, W, _ = pics_train.shape\n",
    "F = H * W\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) La Arquitectura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La arquitectura, como se dijo antes, va a ser una red de capas densas unicamente (o *fully-connected*):\n",
    "\n",
    "![img](https://chsasank.github.io/assets/images/crash_course/mnist_net.png)\n",
    "\n",
    "La entrada de la red (el *input*) va a ser un vector aplanado de tamaño 28x28. Corresponde a aplanar los valores de cada pixel en un unico vector de 1 dimension. El *output* de la red van a ser 10 valores correspondientes a los *scores* de cada clase.\n",
    "\n",
    "El flujo sería el siguiente:\n",
    "\n",
    "1. Tomamos una imagen de 28x28.\n",
    "2. Se aplana en un vector de una dimension.\n",
    "3. Se introduce en la red y fluye hacia la capa de salida.\n",
    "4. La capa de salida va a ser un vector de 10 elementos, donde cada uno representa un *score* de que esa imagen pertenezca a esa clase. Cuanto mayor sea el *score*, buscamos que sea más probable que la imagen pertenezca a esa clase (es decir, que sea ESE digito). Cuando la red esté entrenada, la clase (o el dígito) correcto va a ser aquel que tengo mayor *score*.\n",
    "\n",
    "No vamos a entrar en profundidad en los detalles de implementacion de Tensorflow. Para aquello, puede recurrir a los tutoriales oficiales [aqui](https://www.tensorflow.org/tutorials/), muy simples de seguir y entender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_architecture():\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[None, H, W, 1], name=\"x\")\n",
    "    y = tf.placeholder(tf.uint8, shape=[None, NUM_CLASSES], name=\"y\")\n",
    "    \n",
    "    init = tf.contrib.layers.xavier_initializer()\n",
    "    \n",
    "    out = tf.contrib.layers.flatten(x)\n",
    "\n",
    "    out = tf.layers.dense(out, units=256, activation=tf.nn.relu, kernel_initializer=init)\n",
    "    \n",
    "    out = tf.layers.dense(out, units=256, activation=tf.nn.relu, kernel_initializer=init)\n",
    "    \n",
    "    out = tf.layers.dense(out, units=256, activation=tf.nn.relu, kernel_initializer=init)\n",
    "    \n",
    "    out = tf.layers.dense(out, units=NUM_CLASSES, kernel_initializer=init, name=\"out\")\n",
    "    \n",
    "    return x, y, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) La función de costo (*loss*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funcion de costo para este problema va a ser la entropía cruzada aplicada a la funcion softmax sobre la capa de salida. Expliquemos un poco esto:\n",
    "\n",
    "En primer lugar, se computa la funcion softmax sobre la capa de salida (que son los *scores* de las clases). Esta funcion tiene la siguiente pinta:\n",
    "\n",
    "![img](https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3)\n",
    "\n",
    "Esta funcion mapea los *scores* a una distribucion de probabilidad, intensificando el valor del maximo (por ejemplo, si los scores hubieran sido [1.3, -0.2, 5.2], la funcion daria un vector ~[0.0197, 0.0044, 0.976]. Ahora, el *output* de la red está en terminos de probabilidad, al igual que el *ground truth*! (acuerdense que está en formato *One-hot encoding*).\n",
    "\n",
    "Gracias a esto, definimos la entropia cruzada, que es una forma de relacionar dos distribuciones de probabilidad:\n",
    "\n",
    "![img](https://wikimedia.org/api/rest_v1/media/math/render/svg/0cb6da032ab424eefdca0884cd4113fe578f4293)\n",
    "\n",
    "En resumen, cuando la probabilidad de la clase correcta en el *output* sea relativamente baja, la entropia cruzada va a ser altisima. Cuando sea alta, la entropia va a ser baja. Vamos a intentar minimizar la *loss* (que es la entropia cruzada luego del softmax), para buscar este ultimo comportamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_loss(y, out):\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=out, name=\"mean_loss\")\n",
    "    loss = tf.reduce_mean(loss, name=\"loss\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La *accuracy* mide el porcentaje de eficacia entre los *labels* y el *output* de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_accuracy(y, out):\n",
    "    pred = tf.argmax(out, axis=-1)\n",
    "    gt = tf.argmax(y, axis=-1)\n",
    "    \n",
    "    matches = tf.equal(pred, gt)\n",
    "    \n",
    "    return tf.reduce_mean(tf.cast(matches, tf.float32), name=\"acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) La elección del minimizador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a estar utilizando Gradiente Descendente Estocástico, comúnmente conocido como *Stochastic Gradient Descent* (SGD) con un *learning rate* de 10e-3.\n",
    "\n",
    "Para más información acerca de los minimizadores, leer el siguiente excelente blog [aqui](http://ruder.io/optimizing-gradient-descent/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trainer(loss):\n",
    "    opt = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    return opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones complementarias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siguientes funciones son complementarias y no revisten de mayor importancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_scalars(m):\n",
    "    for k, v in m.items():\n",
    "        tf.summary.scalar(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_images(m):\n",
    "    for k, v in m.items():\n",
    "        tf.summary.image(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainable_parameters():\n",
    "    total_parameters = 0\n",
    "    for variable in tf.trainable_variables():\n",
    "        # shape is an array of tf.Dimension\n",
    "        shape = variable.get_shape()\n",
    "        variable_parameters = 1\n",
    "        for dim in shape:\n",
    "            variable_parameters *= dim.value\n",
    "        total_parameters += variable_parameters\n",
    "    return total_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente funcion junta todos los pasos anteriores para definir el modelo final. Esta funcion es la encargada de cargar el grafo en Tensorflow para luego correr la optimizacion.\n",
    "\n",
    "La funcion retorna aquellos nodos del grafo necesarios para ser corridos luego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    x, y, out = load_architecture()\n",
    "    loss = load_loss(y, out)\n",
    "    acc = load_accuracy(y, out)\n",
    "    upd = load_trainer(loss)\n",
    "    \n",
    "    register_scalars({\"info_loss\": loss, \"info_acc\": acc})\n",
    "    register_images({\"input\": x})\n",
    "\n",
    "    info = tf.summary.merge_all()\n",
    "    \n",
    "    return x, y, out, loss, acc, upd, info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow requiere:\n",
    "\n",
    "1. Definir el grafo computacional (lo que hicimos antes)\n",
    "2. Correr el grafo a traves de una `Session`.\n",
    "\n",
    "A continuacion, definimos la sesión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_session():\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    return sess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, definimos una funcion que encapsula todo el entrenamiento de la red, es decir, la optimizacion de la funcion de *loss* definida previamente.\n",
    "\n",
    "Esta funcion recibe la sesion, el modelo, la data, la cantidad de epocas, el tamaño del *batch* (para SGD) y los *writers*, que sirven para hacer uso de la herramienta de visualizacion *tensorboard*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sess, model, pics_train, labels_train, pics_val, labels_val, epochs, batch_size, train_writer, val_writer):\n",
    "    N, _, _, _ = pics_train.shape\n",
    "    idxs = np.arange(N)\n",
    "    \n",
    "    x, y, out, loss, acc, upd, info = model\n",
    "        \n",
    "    i=0\n",
    "\n",
    "    for ep in tqdm(range(epochs)):\n",
    "        np.random.shuffle(idxs)\n",
    "        pics_train = pics_train[idxs]\n",
    "        labels_train = labels_train[idxs]\n",
    "\n",
    "        for b in range(0, N, batch_size):\n",
    "            X_batch = pics_train[b:b+batch_size]\n",
    "            Y_batch = labels_train[b:b+batch_size]\n",
    "\n",
    "            if X_batch.shape[0] < BATCH_SIZE:\n",
    "                break\n",
    "\n",
    "            graph_info, _ = sess.run([info, upd], feed_dict={x: X_batch, y: Y_batch})\n",
    "            train_writer.add_summary(graph_info, i)\n",
    "            \n",
    "            graph_info, = sess.run([info], feed_dict={x: pics_val, y: labels_val})\n",
    "            val_writer.add_summary(graph_info, i)\n",
    "            \n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ultimo, definimos una funcion que nos va a permitir probar el modelo entrenado. Esta funcion simplemente ejecuta la red con las imagenes que se proveen como parametro. Retorna las inferencias (es decir, las clases \"ganadoras\") para cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(imgs, sess, model):\n",
    "    x, y, out, loss, acc, upd, info = model\n",
    "\n",
    "    N, H, W, _ = imgs.shape\n",
    "    fig=plt.figure(figsize=(10, 10))\n",
    "    columns = 3\n",
    "    rows = 3\n",
    "    for i in range(1, columns*rows +1):\n",
    "        idx = np.random.choice(range(N)) \n",
    "        img = imgs[idx].reshape((1, H, W, 1))\n",
    "        graph_out, = sess.run([out], feed_dict={x: img})\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(np.squeeze(img), cmap=\"gray\")\n",
    "        plt.title(np.argmax(np.squeeze(graph_out)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corriendo el entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usemos las funciones definidas anteriormente y carguemos el modelo, para luego crear una sesión sobre ese modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ionatan\\AppData\\Local\\Temp/ipykernel_1548/2466520490.py:2: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ionatan\\AppData\\Local\\Temp/ipykernel_1548/2466520490.py:4: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001B96103BB38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001B96103BB38>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001B96103BB38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x000001B96103BB38>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From C:\\Users\\Ionatan\\AppData\\Local\\Temp/ipykernel_1548/2466520490.py:11: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B96103BEB8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B96103BEB8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B96103BEB8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B96103BEB8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B960A12BE0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B960A12BE0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B960A12BE0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B960A12BE0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B960A12BE0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B960A12BE0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B960A12BE0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B960A12BE0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B960A12BE0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B960A12BE0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B960A12BE0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000001B960A12BE0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From C:\\Users\\Ionatan\\AppData\\Local\\Temp/ipykernel_1548/4023765988.py:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ionatan\\AppData\\Local\\Temp/ipykernel_1548/4270328455.py:2: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ionatan\\AppData\\Local\\Temp/ipykernel_1548/2720950021.py:3: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ionatan\\AppData\\Local\\Temp/ipykernel_1548/943670041.py:3: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ionatan\\AppData\\Local\\Temp/ipykernel_1548/2713692041.py:10: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ionatan\\AppData\\Local\\Temp/ipykernel_1548/1143740480.py:2: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ionatan\\AppData\\Local\\Temp/ipykernel_1548/1143740480.py:3: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ionatan\\AppData\\Local\\Temp/ipykernel_1548/4047794902.py:3: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "Trainable parameters: 335114\n"
     ]
    }
   ],
   "source": [
    "model = load_model()\n",
    "sess = load_session()\n",
    "print(\"Trainable parameters: {}\".format(trainable_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, corramos el entrenamiento. El siguiente paso va a llevar un tiempo... (dependiendo tambien si estan corriendo en GPU o CPU). Paciencia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ionatan\\AppData\\Local\\Temp/ipykernel_1548/4074797355.py:5: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/70 [01:01<1:10:12, 61.06s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1548/4074797355.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mv_writer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLOGS_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"all\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"val\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpics_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpics_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_writer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv_writer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1548/1985632454.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(sess, model, pics_train, labels_train, pics_val, labels_val, epochs, batch_size, train_writer, val_writer)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mtrain_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mgraph_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpics_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabels_val\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mval_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1354\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 70\n",
    "BATCH_SIZE = 64\n",
    "LOGS_DIR = \"logs\"\n",
    "\n",
    "t_writer = tf.summary.FileWriter(os.path.join(LOGS_DIR, \"all\", \"train\"), graph=sess.graph)\n",
    "v_writer = tf.summary.FileWriter(os.path.join(LOGS_DIR, \"all\", \"val\"), graph=sess.graph)\n",
    "\n",
    "train(sess, model, pics_train, labels_train, pics_test, labels_test, EPOCHS, BATCH_SIZE, t_writer, v_writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la carpeta `logs` van a poder tener informacion util para analizar el proceso de entrenamiento. Para verla, se necesita levantar `tensorboard`. Para esto, ir a la consola y ejecutar:\n",
    "\n",
    "```\n",
    "$ tensorboard --logdir ./logs\n",
    "```\n",
    "\n",
    "Se les va a abrir un *tab* en el navegador donde van a poder ver los graficos de entrenamiento en funcion de las épocas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando inferencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llegamos a la parte mejor parte: **usar el modelo**. Veamos algunas predicciones sobre el set de *training*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(pics_train, sess, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiene mucho sentido que tenga una *performance* perfecta pues la red esta entrenada para identificar estos ejemplos puntuales. Medir la *performance* en el dataset de *training* no está aceptado como práctica, pues no es un indicador \"honesto\". \n",
    "\n",
    "Corramos la red para los ejemplos que la red no vió antes, es decir, los de *testing*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(pics_test, sess, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Midamos el *accuracy* final de nuestro modelo sobre todo el set de *testing*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, out, loss, acc, upd, info = model\n",
    "\n",
    "N, H, W, _ = pics_test.shape\n",
    "graph_out, = sess.run([acc], feed_dict={x: pics_test, y: labels_test})\n",
    "print(\"Overall accuracy: {0:.2f}%\".format(100 * np.squeeze(graph_out)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
